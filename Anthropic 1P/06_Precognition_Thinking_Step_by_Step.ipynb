{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Precognition (Thinking Step by Step)\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (0.72.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from anthropic) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from anthropic) (0.17.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from anthropic) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from anthropic) (2.12.4)\n",
      "Requirement already satisfied: sniffio in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from anthropic) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
      "Requirement already satisfied: certifi in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /workspaces/prompt-eng-interactive-tutorial/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic\n",
    "\n",
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "import anthropic\n",
    "\n",
    "# Retrieve the API_KEY & MODEL_NAME variables from the IPython store\n",
    "%store -r API_KEY\n",
    "%store -r MODEL_NAME\n",
    "\n",
    "client = anthropic.Anthropic(api_key=API_KEY)\n",
    "\n",
    "def get_completion(prompt: str, system_prompt=\"\", prefill=\"\"):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt},\n",
    "          {\"role\": \"assistant\", \"content\": prefill}\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "If someone woke you up and immediately started asking you several complicated questions that you had to respond to right away, how would you do? Probably not as good as if you were given time to **think through your answer first**. \n",
    "\n",
    "Guess what? Claude is the same way.\n",
    "\n",
    "**Giving Claude time to think step by step sometimes makes Claude more accurate**, particularly for complex tasks. However, **thinking only counts when it's out loud**. You cannot ask Claude to think but output only the answer - in this case, no thinking has actually occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "In the prompt below, it's clear to a human reader that the second sentence belies the first. But **Claude takes the word \"unrelated\" too literally**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of this movie review is positive.\n",
      "\n",
      "The first part of the review states that the movie \"blew my mind with its freshness and originality\", which indicates a very positive reaction to the film.\n",
      "\n",
      "The second part about living under a rock since 1900 is likely meant as a humorous or sarcastic remark, but it does not negate the overall positive sentiment expressed in the first part of the review.\n",
      "\n",
      "So based on the language used, this can be considered a positive movie review, despite the somewhat tongue-in-cheek final statement.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"\"\"Is this movie review sentiment positive or negative?\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since the year 1900.\"\"\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve Claude's response, let's **allow Claude to think things out first before answering**. We do that by literally spelling out the steps that Claude should take in order to process and think through its task. Along with a dash of role prompting, this empowers Claude to understand the review more deeply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<positive-argument>\n",
      "The review suggests that the movie is highly innovative and refreshing, which could be seen as a positive sentiment. The reviewer's statement about living under a rock since 1900 implies that the movie is so original and groundbreaking that it has caught the reviewer by surprise, suggesting a level of creativity and uniqueness that is often praised in film reviews.\n",
      "</positive-argument>\n",
      "\n",
      "<negative-argument>\n",
      "The reviewer's self-deprecating comment about living under a rock since 1900 could also be interpreted as a negative sentiment, implying that the movie's \"freshness and originality\" are not actually new or innovative, but rather something the reviewer has been unaware of for a very long time. This could suggest that the reviewer's praise for the movie's originality is not entirely genuine or well-informed.\n",
      "</negative-argument>\n",
      "\n",
      "Based on the arguments presented, the sentiment of the review is ambiguous. The positive and negative interpretations both have merit, and the reviewer's statement about living under a rock since 1900 could be seen as either a genuine expression of surprise and delight or a self-deprecating acknowledgment of their own lack of awareness. Without more context, it is difficult to determine the overall sentiment of the review.\n"
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a savvy reader of movie reviews.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"\"\"Is this review sentiment positive or negative? First, write the best arguments for each side in <positive-argument> and <negative-argument> XML tags, then answer.\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since 1900.\"\"\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Claude is sometimes sensitive to ordering**. This example is on the frontier of Claude's ability to understand nuanced text, and when we swap the order of the arguments from the previous example so that negative is first and positive is second, this changes Claude's overall assessment to positive.\n",
    "\n",
    "In most situations (but not all, confusingly enough), **Claude is more likely to choose the second of two options**, possibly because in its training data from the web, second options were more likely to be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<negative-argument>\n",
      "The statement \"This movie blew my mind with its freshness and originality\" could be interpreted as sarcastic, implying that the movie was actually unoriginal and unimpressive. The second part of the review, \"Unrelatedly, I have been living under a rock since 1900,\" further suggests that the reviewer is being sarcastic and implying that the movie is not at all fresh or original, but rather outdated and unimpressive.\n",
      "</negative-argument>\n",
      "\n",
      "<positive-argument>\n",
      "The statement \"This movie blew my mind with its freshness and originality\" could be taken at face value, indicating that the reviewer genuinely found the movie to be innovative and engaging. The second part of the review, \"Unrelatedly, I have been living under a rock since 1900,\" could be interpreted as a lighthearted acknowledgment of the reviewer's own lack of exposure to recent films, rather than a criticism of the movie itself.\n",
      "</positive-argument>\n",
      "\n",
      "Since the statement \"This movie blew my mind with its freshness and originality\" is likely intended to be sarcastic, the overall sentiment of the review is negative.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"\"\"Is this review sentiment negative or positive? First write the best arguments for each side in <negative-argument> and <positive-argument> XML tags, then whenever someone uses sarcasm in a statement, assume the intended meaning is negative or critical, even if the words are positive, then make a decision based on whether the statment is sarcastic\n",
    "\n",
    "This movie blew my mind with its freshness and originality. Unrelatedly, I have been living under a rock since 1900.\"\"\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Letting Claude think can shift Claude's answer from incorrect to correct**. It's that simple in many cases where Claude makes mistakes!\n",
    "\n",
    "Let's go through an example where Claude's answer is incorrect to see how asking Claude to think can fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a famous movie starring an actor born in 1956:\n",
      "\n",
      "The Shawshank Redemption (1994) starring Tim Robbins. Tim Robbins was born on October 16, 1958.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix this by asking Claude to think step by step, this time in `<brainstorm>` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<brainstorm>\n",
      "- Tom Hanks (born July 9, 1956)\n",
      "- Denzel Washington (born December 28, 1954)\n",
      "- Sigourney Weaver (born October 8, 1949)\n",
      "- Bill Murray (born September 21, 1950)\n",
      "</brainstorm>\n",
      "\n",
      "The actor born in 1956 is Tom Hanks. A famous movie starring Tom Hanks is Forrest Gump (1994).\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956. First brainstorm about some actors born in 1956 and their birth years in <brainstorm> tags, then Ensure that the actor is actually born on the day specified, then pick the first actor\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to experiment with the lesson prompts without changing any content above, scroll all the way to the bottom of the lesson notebook to visit the [**Example Playground**](#example-playground)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "- [Exercise 6.1 - Classifying Emails](#exercise-61---classifying-emails)\n",
    "- [Exercise 6.2 - Email Classification Formatting](#exercise-62---email-classification-formatting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1 - Classifying Emails\n",
    "In this exercise, we'll be instructing Claude to sort emails into the following categories:\t\t\t\t\t\t\t\t\t\t\n",
    "- (A) Pre-sale question\n",
    "- (B) Broken or defective item\n",
    "- (C) Billing question\n",
    "- (D) Other (please explain)\n",
    "\n",
    "For the first part of the exercise, change the `PROMPT` to **make Claude output the correct classification and ONLY the classification**. Your answer needs to **include the letter (A - D) of the correct choice, with the parentheses, as well as the name of the category**.\n",
    "\n",
    "Refer to the comments beside each email in the `EMAILS` list to know which category that email should be classified under."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:29: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\)'\n",
      "/tmp/ipykernel_2243/1076638048.py:29: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  \"A\": \"A\\) P\",\n",
      "/tmp/ipykernel_2243/1076638048.py:30: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  \"B\": \"B\\) B\",\n",
      "/tmp/ipykernel_2243/1076638048.py:31: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  \"C\": \"C\\) B\",\n",
      "/tmp/ipykernel_2243/1076638048.py:32: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  \"D\": \"D\\) O\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please classify this email as either (A) Pre-sale question\n",
      "- (B) Broken or defective item\n",
      "- (C) Billing question\n",
      "- (D) Other (please explain): \n",
      "Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\n",
      "\n",
      "ASSISTANT TURN\n",
      "The email is a:\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      " (B) Broken or defective item\n",
      "\n",
      "The email describes an issue with the Mixmaster4000 product, where it is producing a strange noise, emitting a smoky and plasticky smell, and the user needs a replacement. This indicates that the product is broken or defective, and the user is seeking a resolution for the issue, which falls under the \"Broken or defective item\" category.\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please classify this email as either (A) Pre-sale question\n",
      "- (B) Broken or defective item\n",
      "- (C) Billing question\n",
      "- (D) Other (please explain): \n",
      "Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\n",
      "\n",
      "ASSISTANT TURN\n",
      "The email is a:\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      " (A) Pre-sale question\n",
      "\n",
      "The email is asking about the capabilities of the Mixmaster 4000 and whether it can be used to mix paint, which suggests the user is considering purchasing the product and wants to know if it can be used for that purpose. This is a pre-sale question, as the user is inquiring about the product's features before making a purchase decision.\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please classify this email as either (A) Pre-sale question\n",
      "- (B) Broken or defective item\n",
      "- (C) Billing question\n",
      "- (D) Other (please explain): \n",
      "I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\n",
      "\n",
      "ASSISTANT TURN\n",
      "The email is a:\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      " (C) Billing question\n",
      "\n",
      "The email is clearly expressing frustration with ongoing monthly charges after cancelling a service, which indicates a billing-related issue.\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please classify this email as either (A) Pre-sale question\n",
      "- (B) Broken or defective item\n",
      "- (C) Billing question\n",
      "- (D) Other (please explain): \n",
      "How did I get here I am not good with computer.  Halp.\n",
      "\n",
      "ASSISTANT TURN\n",
      "The email is a:\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      " (D) Other\n",
      "\n",
      "The email does not seem to be asking a pre-sale question, reporting a broken or defective item, or asking a billing question. Instead, it appears to be a general request for help, expressing confusion about how the person ended up in their current situation and not being good with computers. This would classify it as an \"Other\" type of email that does not fit into the specific categories provided.\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = \"\"\"Please classify this email as either (A) Pre-sale question\n",
    "- (B) Broken or defective item\n",
    "- (C) Billing question\n",
    "- (D) Other (please explain): \n",
    "{email}\"\"\"\n",
    "\n",
    "# Prefill for Claude's response, if any\n",
    "PREFILL = \"The email is a:\"\n",
    "\n",
    "# Variable content stored as a list\n",
    "EMAILS = [\n",
    "    \"Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\", # (B) Broken or defective item\n",
    "    \"Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\", # (A) Pre-sale question OR (D) Other (please explain)\n",
    "    \"I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\", # (C) Billing question\n",
    "    \"How did I get here I am not good with computer.  Halp.\" # (D) Other (please explain)\n",
    "]\n",
    "\n",
    "# Correct categorizations stored as a list of lists to accommodate the possibility of multiple correct categorizations per email\n",
    "ANSWERS = [\n",
    "    [\"B\"],\n",
    "    [\"A\",\"D\"],\n",
    "    [\"C\"],\n",
    "    [\"D\"]\n",
    "]\n",
    "\n",
    "# Dictionary of string values for each category to be used for regex grading\n",
    "REGEX_CATEGORIES = {\n",
    "    \"A\": \"A\\) P\",\n",
    "    \"B\": \"B\\) B\",\n",
    "    \"C\": \"C\\) B\",\n",
    "    \"D\": \"D\\) O\"\n",
    "}\n",
    "\n",
    "# Iterate through list of emails\n",
    "for i,email in enumerate(EMAILS):\n",
    "    \n",
    "    # Substitute the email text into the email placeholder variable\n",
    "    formatted_prompt = PROMPT.format(email=email)\n",
    "   \n",
    "    # Get Claude's response\n",
    "    response = get_completion(formatted_prompt, prefill=PREFILL)\n",
    "\n",
    "    # Grade Claude's response\n",
    "    grade = any([bool(re.search(REGEX_CATEGORIES[ans], response)) for ans in ANSWERS[i]])\n",
    "    \n",
    "    # Print Claude's response\n",
    "    print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "    print(\"USER TURN\")\n",
    "    print(formatted_prompt)\n",
    "    print(\"\\nASSISTANT TURN\")\n",
    "    print(PREFILL)\n",
    "    print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "    print(response)\n",
    "    print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "    print(\"This exercise has been correctly solved:\", grade, \"\\n\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grading function in this exercise is looking for the correct categorization letter + the closing parentheses and the first letter of the name of the category, such as \"C) B\" or \"B) B\" etc.\n",
      "Let's take this exercise step by step:\t\t\t\t\t\t\t\t\t\t\n",
      "1.\tHow will Claude know what categories you want to use? Tell it! Include the four categories you want directly in the prompt. Be sure to include the parenthetical letters as well for easy classification. Feel free to use XML tags to organize your prompt and make clear to Claude where the categories begin and end.\t\t\t\t\t\t\t\t\t\n",
      "2.\tTry to cut down on superfluous text so that Claude immediately answers with the classification and ONLY the classification. There are several ways to do this, from speaking for Claude (providing anything from the beginning of the sentence to a single open parenthesis so that Claude knows you want the parenthetical letter as the first part of the answer) to telling Claude that you want the classification and only the classification, skipping the preamble.\n",
      "Refer to Chapters 2 and 5 if you want a refresher on these techniques.\t\t\t\t\t\t\t\n",
      "3.\tClaude may still be incorrectly categorizing or not including the names of the categories when it answers. Fix this by telling Claude to include the full category name in its answer.)\t\t\t\t\t\t\t\t\n",
      "4.\tBe sure that you still have {email} somewhere in your prompt template so that we can properly substitute in emails for Claude to evaluate.\n"
     ]
    }
   ],
   "source": [
    "from hints import exercise_6_1_hint; print(exercise_6_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still stuck? Run the cell below for an example solution.\t\t\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_6_1_solution; print(exercise_6_1_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2 - Email Classification Formatting\n",
    "In this exercise, we're going to refine the output of the above prompt to yield an answer formatted exactly how we want it. \n",
    "\n",
    "Use your favorite output formatting technique to make Claude wrap JUST the letter of the correct classification in `<answer></answer>` tags. For instance, the answer to the first email should contain the exact string `<answer>B</answer>`.\n",
    "\n",
    "Refer to the comments beside each email in the `EMAILS` list if you forget which letter category is correct for each email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please classify this email as either Please classify this email as either (A) Pre-sale question\n",
      "- (B) Broken or defective item\n",
      "- (C) Billing question\n",
      "- (D) Other (please explain): \n",
      "Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement., then put the answer letter without parentheses in <answer> tags only\n",
      "\n",
      "ASSISTANT TURN\n",
      "The answer, in xml tags is:\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      " <answer>B</answer>\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please classify this email as either Please classify this email as either (A) Pre-sale question\n",
      "- (B) Broken or defective item\n",
      "- (C) Billing question\n",
      "- (D) Other (please explain): \n",
      "Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?, then put the answer letter without parentheses in <answer> tags only\n",
      "\n",
      "ASSISTANT TURN\n",
      "The answer, in xml tags is:\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      " <answer>A</answer>\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please classify this email as either Please classify this email as either (A) Pre-sale question\n",
      "- (B) Broken or defective item\n",
      "- (C) Billing question\n",
      "- (D) Other (please explain): \n",
      "I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???, then put the answer letter without parentheses in <answer> tags only\n",
      "\n",
      "ASSISTANT TURN\n",
      "The answer, in xml tags is:\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      " <answer>C</answer>\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please classify this email as either Please classify this email as either (A) Pre-sale question\n",
      "- (B) Broken or defective item\n",
      "- (C) Billing question\n",
      "- (D) Other (please explain): \n",
      "How did I get here I am not good with computer.  Halp., then put the answer letter without parentheses in <answer> tags only\n",
      "\n",
      "ASSISTANT TURN\n",
      "The answer, in xml tags is:\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      " <answer>D</answer>\n",
      "\n",
      "This email does not seem to be related to a pre-sale question, a broken or defective item, or a billing question. Instead, it appears to be a general request for help or assistance with using a computer, which would fall under the \"Other\" category.\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = \"\"\"Please classify this email as either Please classify this email as either (A) Pre-sale question\n",
    "- (B) Broken or defective item\n",
    "- (C) Billing question\n",
    "- (D) Other (please explain): \n",
    "{email}, then put the answer letter without parentheses in <answer> tags only\"\"\"\n",
    "\n",
    "# Prefill for Claude's response, if any\n",
    "PREFILL = \"The answer, in xml tags is:\"\n",
    "\n",
    "# Variable content stored as a list\n",
    "EMAILS = [\n",
    "    \"Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\", # (B) Broken or defective item\n",
    "    \"Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\", # (A) Pre-sale question OR (D) Other (please explain)\n",
    "    \"I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\", # (C) Billing question\n",
    "    \"How did I get here I am not good with computer.  Halp.\" # (D) Other (please explain)\n",
    "]\n",
    "\n",
    "# Correct categorizations stored as a list of lists to accommodate the possibility of multiple correct categorizations per email\n",
    "ANSWERS = [\n",
    "    [\"B\"],\n",
    "    [\"A\",\"D\"],\n",
    "    [\"C\"],\n",
    "    [\"D\"]\n",
    "]\n",
    "\n",
    "# Dictionary of string values for each category to be used for regex grading\n",
    "REGEX_CATEGORIES = {\n",
    "    \"A\": \"<answer>A</answer>\",\n",
    "    \"B\": \"<answer>B</answer>\",\n",
    "    \"C\": \"<answer>C</answer>\",\n",
    "    \"D\": \"<answer>D</answer>\"\n",
    "}\n",
    "\n",
    "# Iterate through list of emails\n",
    "for i,email in enumerate(EMAILS):\n",
    "    \n",
    "    # Substitute the email text into the email placeholder variable\n",
    "    formatted_prompt = PROMPT.format(email=email)\n",
    "   \n",
    "    # Get Claude's response\n",
    "    response = get_completion(formatted_prompt, prefill=PREFILL)\n",
    "\n",
    "    # Grade Claude's response\n",
    "    grade = any([bool(re.search(REGEX_CATEGORIES[ans], response)) for ans in ANSWERS[i]])\n",
    "    \n",
    "    # Print Claude's response\n",
    "    print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "    print(\"USER TURN\")\n",
    "    print(formatted_prompt)\n",
    "    print(\"\\nASSISTANT TURN\")\n",
    "    print(PREFILL)\n",
    "    print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "    print(response)\n",
    "    print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "    print(\"This exercise has been correctly solved:\", grade, \"\\n\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_6_2_hint; print(exercise_6_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "If you've solved all exercises up until this point, you're ready to move to the next chapter. Happy prompting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Playground\n",
    "\n",
    "This is an area for you to experiment freely with the prompt examples shown in this lesson and tweak prompts to see how it may affect Claude's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of this movie review is positive.\n",
      "\n",
      "The first part of the review states that the movie \"blew my mind with its freshness and originality\", which indicates a very positive reaction to the film.\n",
      "\n",
      "The second part about living under a rock since 1900 is likely a humorous or sarcastic remark, but it does not negate the overall positive sentiment expressed in the first part of the review.\n",
      "\n",
      "So based on the language used, this can be considered a positive movie review, despite the somewhat tongue-in-cheek final statement.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"\"\"Is this movie review sentiment positive or negative?\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since the year 1900.\"\"\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a savvy reader of movie reviews.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"\"\"Is this review sentiment positive or negative? First, write the best arguments for each side in <positive-argument> and <negative-argument> XML tags, then answer.\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since 1900.\"\"\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"\"\"Is this review sentiment negative or positive? First write the best arguments for each side in <negative-argument> and <positive-argument> XML tags, then answer.\n",
    "\n",
    "This movie blew my mind with its freshness and originality. Unrelatedly, I have been living under a rock since 1900.\"\"\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956. First brainstorm about some actors and their birth years in <brainstorm> tags, then give your answer.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
